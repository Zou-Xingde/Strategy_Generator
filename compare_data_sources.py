#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ¯”å°è³‡æ–™åº«æ•¸æ“šå’Œå‰ç«¯APIæ•¸æ“š
æ‰¾å‡ºæ•¸æ“šå·®ç•°å’Œå•é¡Œæ‰€åœ¨
"""

import sys
import os
import pandas as pd
import requests
import json
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config.settings import DUCKDB_PATH
from src.database.connection import DuckDBConnection

def get_database_data(symbol='XAUUSD', timeframe='D1', limit=100):
    """å¾è³‡æ–™åº«ç²å–æ•¸æ“š"""
    print(f"ğŸ“Š å¾è³‡æ–™åº«ç²å– {symbol} {timeframe} æ•¸æ“š...")
    
    try:
        with DuckDBConnection(str(DUCKDB_PATH)) as db:
            conn = db.conn
            
            query = f"""
            SELECT 
                timestamp,
                open,
                high,
                low,
                close,
                volume
            FROM candlestick_data_new 
            WHERE symbol = '{symbol}' 
            AND timeframe = '{timeframe}'
            ORDER BY timestamp DESC
            LIMIT {limit}
            """
            
            df = pd.read_sql_query(query, conn)
            
            if df.empty:
                print(f"âŒ è³‡æ–™åº«ä¸­æ²’æœ‰æ‰¾åˆ° {symbol} {timeframe} çš„æ•¸æ“š")
                return None
            
            print(f"âœ… å¾è³‡æ–™åº«ç²å–åˆ° {len(df)} æ¢æ•¸æ“š")
            return df
            
    except Exception as e:
        print(f"âŒ å¾è³‡æ–™åº«ç²å–æ•¸æ“šå¤±æ•—: {e}")
        return None

def get_api_data(symbol='XAUUSD', timeframe='D1', limit=100):
    """å¾APIç²å–æ•¸æ“š"""
    print(f"ğŸŒ å¾APIç²å– {symbol} {timeframe} æ•¸æ“š...")
    
    try:
        url = f"http://127.0.0.1:8050/api/candlestick/{symbol}/{timeframe}?limit={limit}"
        print(f"API URL: {url}")
        
        response = requests.get(url, timeout=30)
        
        if response.status_code != 200:
            print(f"âŒ APIè«‹æ±‚å¤±æ•—: {response.status_code}")
            return None
        
        data = response.json()
        
        if 'error' in data:
            print(f"âŒ APIè¿”å›éŒ¯èª¤: {data['error']}")
            return None
        
        if 'data' not in data or not data['data']:
            print(f"âŒ APIè¿”å›ç©ºæ•¸æ“š")
            return None
        
        # è½‰æ›ç‚ºDataFrame
        df = pd.DataFrame(data['data'])
        
        if df.empty:
            print(f"âŒ APIè¿”å›çš„æ•¸æ“šç‚ºç©º")
            return None
        
        print(f"âœ… å¾APIç²å–åˆ° {len(df)} æ¢æ•¸æ“š")
        return df
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ APIè«‹æ±‚ç•°å¸¸: {e}")
        return None
    except Exception as e:
        print(f"âŒ è™•ç†APIæ•¸æ“šå¤±æ•—: {e}")
        return None

def compare_data_sources(symbol='XAUUSD', timeframe='D1', limit=100):
    """æ¯”å°è³‡æ–™åº«å’ŒAPIæ•¸æ“š"""
    print(f"\nğŸ” æ¯”å° {symbol} {timeframe} æ•¸æ“šä¾†æº...")
    print("=" * 80)
    
    # ç²å–è³‡æ–™åº«æ•¸æ“š
    db_df = get_database_data(symbol, timeframe, limit)
    if db_df is None:
        return
    
    # ç²å–APIæ•¸æ“š
    api_df = get_api_data(symbol, timeframe, limit)
    if api_df is None:
        return
    
    print(f"\nğŸ“‹ æ•¸æ“šæ¦‚æ³:")
    print(f"   è³‡æ–™åº«æ•¸æ“š: {len(db_df)} æ¢")
    print(f"   APIæ•¸æ“š: {len(api_df)} æ¢")
    
    # æ¨™æº–åŒ–æ•¸æ“šæ ¼å¼
    print(f"\nğŸ”„ æ¨™æº–åŒ–æ•¸æ“šæ ¼å¼...")
    
    # è³‡æ–™åº«æ•¸æ“šæ¨™æº–åŒ–
    db_df_clean = db_df.copy()
    db_df_clean['timestamp'] = pd.to_datetime(db_df_clean['timestamp'])
    db_df_clean = db_df_clean.sort_values('timestamp', ascending=False).reset_index(drop=True)
    
    # APIæ•¸æ“šæ¨™æº–åŒ–
    api_df_clean = api_df.copy()
    api_df_clean['timestamp'] = pd.to_datetime(api_df_clean['timestamp'])
    api_df_clean = api_df_clean.sort_values('timestamp', ascending=False).reset_index(drop=True)
    
    # ç¢ºä¿åˆ—åä¸€è‡´
    column_mapping = {
        'open': 'open',
        'high': 'high', 
        'low': 'low',
        'close': 'close',
        'volume': 'volume'
    }
    
    # é¸æ“‡è¦æ¯”è¼ƒçš„åˆ—
    db_compare = db_df_clean[['timestamp', 'open', 'high', 'low', 'close', 'volume']].copy()
    api_compare = api_df_clean[['timestamp', 'open', 'high', 'low', 'close', 'volume']].copy()
    
    print(f"âœ… æ•¸æ“šæ ¼å¼æ¨™æº–åŒ–å®Œæˆ")
    
    # æ¯”å°æ•¸æ“šæ•¸é‡
    print(f"\nğŸ“Š æ•¸æ“šæ•¸é‡æ¯”å°:")
    print(f"   è³‡æ–™åº«: {len(db_compare)} æ¢")
    print(f"   API: {len(api_compare)} æ¢")
    print(f"   å·®ç•°: {abs(len(db_compare) - len(api_compare))} æ¢")
    
    # æ¯”å°æ™‚é–“ç¯„åœ
    print(f"\nğŸ“… æ™‚é–“ç¯„åœæ¯”å°:")
    print(f"   è³‡æ–™åº«: {db_compare['timestamp'].min()} åˆ° {db_compare['timestamp'].max()}")
    print(f"   API: {api_compare['timestamp'].min()} åˆ° {api_compare['timestamp'].max()}")
    
    # æ‰¾å‡ºå…±åŒçš„æ™‚é–“æˆ³
    db_timestamps = set(db_compare['timestamp'])
    api_timestamps = set(api_compare['timestamp'])
    common_timestamps = db_timestamps.intersection(api_timestamps)
    
    print(f"\nğŸ”— å…±åŒæ™‚é–“æˆ³: {len(common_timestamps)} å€‹")
    
    # æ¯”å°å…±åŒæ™‚é–“æˆ³çš„æ•¸æ“š
    if common_timestamps:
        print(f"\nğŸ” æ¯”å°å…±åŒæ™‚é–“æˆ³çš„æ•¸æ“š...")
        
        # ç¯©é¸å…±åŒæ™‚é–“æˆ³çš„æ•¸æ“š
        db_common = db_compare[db_compare['timestamp'].isin(common_timestamps)].copy()
        api_common = api_compare[api_compare['timestamp'].isin(common_timestamps)].copy()
        
        # æŒ‰æ™‚é–“æˆ³æ’åº
        db_common = db_common.sort_values('timestamp').reset_index(drop=True)
        api_common = api_common.sort_values('timestamp').reset_index(drop=True)
        
        # æ¯”å°åƒ¹æ ¼æ•¸æ“š
        price_columns = ['open', 'high', 'low', 'close']
        differences = []
        
        for col in price_columns:
            # è¨ˆç®—å·®ç•°
            diff = (db_common[col] - api_common[col]).abs()
            max_diff = diff.max()
            mean_diff = diff.mean()
            
            differences.append({
                'column': col,
                'max_diff': max_diff,
                'mean_diff': mean_diff,
                'max_diff_idx': diff.idxmax() if max_diff > 0 else None
            })
            
            print(f"   {col}: æœ€å¤§å·®ç•°={max_diff:.6f}, å¹³å‡å·®ç•°={mean_diff:.6f}")
        
        # æ‰¾å‡ºæœ€å¤§å·®ç•°çš„æ•¸æ“šé»
        max_diff_overall = max(differences, key=lambda x: x['max_diff'])
        if max_diff_overall['max_diff'] > 0.001:  # å¦‚æœå·®ç•°å¤§æ–¼0.001
            idx = max_diff_overall['max_diff_idx']
            if idx is not None:
                print(f"\nâš ï¸  ç™¼ç¾æœ€å¤§å·®ç•°:")
                print(f"   æ™‚é–“: {db_common.loc[idx, 'timestamp']}")
                print(f"   æ¬„ä½: {max_diff_overall['column']}")
                print(f"   è³‡æ–™åº«å€¼: {db_common.loc[idx, max_diff_overall['column']]:.6f}")
                print(f"   APIå€¼: {api_common.loc[idx, max_diff_overall['column']]:.6f}")
                print(f"   å·®ç•°: {max_diff_overall['max_diff']:.6f}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å®Œå…¨ä¸åŒçš„æ•¸æ“š
        print(f"\nğŸ” æª¢æŸ¥æ•¸æ“šä¸€è‡´æ€§...")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å®Œå…¨ä¸åŒçš„æ•¸æ“šé»
        different_data = []
        for i in range(min(len(db_common), len(api_common))):
            db_row = db_common.iloc[i]
            api_row = api_common.iloc[i]
            
            if db_row['timestamp'] != api_row['timestamp']:
                different_data.append({
                    'index': i,
                    'db_timestamp': db_row['timestamp'],
                    'api_timestamp': api_row['timestamp'],
                    'type': 'timestamp_mismatch'
                })
                continue
            
            # æª¢æŸ¥åƒ¹æ ¼å·®ç•°
            for col in price_columns:
                if abs(db_row[col] - api_row[col]) > 0.001:
                    different_data.append({
                        'index': i,
                        'timestamp': db_row['timestamp'],
                        'column': col,
                        'db_value': db_row[col],
                        'api_value': api_row[col],
                        'difference': abs(db_row[col] - api_row[col]),
                        'type': 'price_difference'
                    })
        
        if different_data:
            print(f"âš ï¸  ç™¼ç¾ {len(different_data)} å€‹ä¸åŒçš„æ•¸æ“šé»:")
            for diff in different_data[:10]:  # åªé¡¯ç¤ºå‰10å€‹
                if diff['type'] == 'timestamp_mismatch':
                    print(f"   ç´¢å¼• {diff['index']}: æ™‚é–“æˆ³ä¸åŒ¹é…")
                    print(f"     è³‡æ–™åº«: {diff['db_timestamp']}")
                    print(f"     API: {diff['api_timestamp']}")
                else:
                    print(f"   ç´¢å¼• {diff['index']}: {diff['column']} å·®ç•°")
                    print(f"     æ™‚é–“: {diff['timestamp']}")
                    print(f"     è³‡æ–™åº«: {diff['db_value']:.6f}")
                    print(f"     API: {diff['api_value']:.6f}")
                    print(f"     å·®ç•°: {diff['difference']:.6f}")
                print()
        else:
            print("âœ… å…±åŒæ™‚é–“æˆ³çš„æ•¸æ“šå®Œå…¨ä¸€è‡´")
    
    # æª¢æŸ¥ç¨æœ‰çš„æ•¸æ“š
    db_only = db_timestamps - api_timestamps
    api_only = api_timestamps - db_timestamps
    
    print(f"\nğŸ“ˆ ç¨æœ‰æ•¸æ“šåˆ†æ:")
    print(f"   åƒ…è³‡æ–™åº«æœ‰: {len(db_only)} å€‹æ™‚é–“æˆ³")
    print(f"   åƒ…APIæœ‰: {len(api_only)} å€‹æ™‚é–“æˆ³")
    
    if db_only:
        print(f"   è³‡æ–™åº«ç¨æœ‰æ™‚é–“æˆ³ (å‰5å€‹):")
        for ts in sorted(list(db_only))[:5]:
            print(f"     {ts}")
    
    if api_only:
        print(f"   APIç¨æœ‰æ™‚é–“æˆ³ (å‰5å€‹):")
        for ts in sorted(list(api_only))[:5]:
            print(f"     {ts}")
    
    print(f"\nğŸ“‹ æ¯”å°å®Œæˆ!")

def check_frontend_processing():
    """æª¢æŸ¥å‰ç«¯æ•¸æ“šè™•ç†é‚è¼¯"""
    print(f"\nğŸ” æª¢æŸ¥å‰ç«¯æ•¸æ“šè™•ç†é‚è¼¯...")
    print("=" * 80)
    
    # ç²å–APIåŸå§‹æ•¸æ“š
    api_df = get_api_data('XAUUSD', 'D1', 50)
    if api_df is None:
        return
    
    print(f"\nğŸ“Š APIåŸå§‹æ•¸æ“šæ¨£æœ¬ (å‰5æ¢):")
    print(api_df.head().to_string())
    
    # æ¨¡æ“¬å‰ç«¯è™•ç†é‚è¼¯
    print(f"\nğŸ”„ æ¨¡æ“¬å‰ç«¯è™•ç†é‚è¼¯...")
    
    # 1. æª¢æŸ¥æ•¸æ“šé©—è­‰
    print(f"1. æ•¸æ“šé©—è­‰æª¢æŸ¥:")
    invalid_data = []
    for idx, row in api_df.iterrows():
        if pd.isna(row['timestamp']) or pd.isna(row['open']) or pd.isna(row['high']) or pd.isna(row['low']) or pd.isna(row['close']):
            invalid_data.append(idx)
    
    if invalid_data:
        print(f"   âš ï¸  ç™¼ç¾ {len(invalid_data)} æ¢ç„¡æ•ˆæ•¸æ“š")
    else:
        print(f"   âœ… æ‰€æœ‰æ•¸æ“šéƒ½æœ‰æ•ˆ")
    
    # 2. æª¢æŸ¥æ™‚é–“æˆ³æ ¼å¼
    print(f"2. æ™‚é–“æˆ³æ ¼å¼æª¢æŸ¥:")
    try:
        api_df['timestamp_parsed'] = pd.to_datetime(api_df['timestamp'])
        print(f"   âœ… æ™‚é–“æˆ³è§£ææˆåŠŸ")
    except Exception as e:
        print(f"   âŒ æ™‚é–“æˆ³è§£æå¤±æ•—: {e}")
    
    # 3. æª¢æŸ¥æ•¸æ“šæ’åº
    print(f"3. æ•¸æ“šæ’åºæª¢æŸ¥:")
    api_df_sorted = api_df.sort_values('timestamp')
    is_sorted = api_df_sorted.equals(api_df)
    print(f"   {'âœ…' if is_sorted else 'âš ï¸'} æ•¸æ“š{'å·²' if is_sorted else 'æœª'}æ’åº")
    
    # 4. æª¢æŸ¥æ•¸æ“šå»é‡
    print(f"4. æ•¸æ“šå»é‡æª¢æŸ¥:")
    duplicates = api_df.duplicated(subset=['timestamp']).sum()
    print(f"   {'âš ï¸' if duplicates > 0 else 'âœ…'} ç™¼ç¾ {duplicates} å€‹é‡è¤‡æ™‚é–“æˆ³")
    
    # 5. æª¢æŸ¥åƒ¹æ ¼é‚è¼¯
    print(f"5. åƒ¹æ ¼é‚è¼¯æª¢æŸ¥:")
    invalid_prices = []
    for idx, row in api_df.iterrows():
        if row['high'] < max(row['open'], row['close']) or row['low'] > min(row['open'], row['close']):
            invalid_prices.append(idx)
    
    if invalid_prices:
        print(f"   âš ï¸  ç™¼ç¾ {len(invalid_prices)} æ¢åƒ¹æ ¼é‚è¼¯éŒ¯èª¤")
    else:
        print(f"   âœ… åƒ¹æ ¼é‚è¼¯æ­£ç¢º")

if __name__ == "__main__":
    print("ğŸ” æ•¸æ“šä¾†æºæ¯”å°å·¥å…·")
    print("=" * 60)
    
    # æ¯”å°æ•¸æ“šä¾†æº
    compare_data_sources('XAUUSD', 'D1', 100)
    
    # æª¢æŸ¥å‰ç«¯è™•ç†é‚è¼¯
    check_frontend_processing() 