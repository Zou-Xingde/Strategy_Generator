#!/usr/bin/env python3
"""
rebuild_database.py
-------------------
1. é€£æ¥ DuckDBï¼Œå‚™ä»½èˆŠè³‡æ–™åº«æª”ã€‚
2. æ¸…ç©ºæ‰€æœ‰äº‹å‹™æ€§è³‡æ–™è¡¨ (candlestick/tick/swing/statistics)ã€‚
3. é‡æ–°åŒ¯å…¥ä¸‰å€‹å•†å“ Tick CSVï¼Œè¨ˆç®— M1~D1 å¤šé€±æœŸ K ç·šï¼Œå¯«å…¥ candlestick_data_newã€‚
   (æ¼”ç¤º: åªè¨ˆç®— M1, M5, M15, M30, H1, H4, D1ï¼Œè‹¥è¦æ›´å¤šå¯è‡ªè¡Œæ“´å……)
4. æ›´æ–° symbols è¡¨ã€‚
5. é‡å»º v_candlestick_latest è¦–åœ–ã€‚

æ³¨æ„: æ­¤è…³æœ¬ç¤ºç¯„æµç¨‹ï¼Œå·¨é‡ Tick CSV å¯èƒ½éœ€è¦èª¿æ•´ chunksize èˆ‡è¨˜æ†¶é«”ã€‚
"""
import os
import sys
import shutil
from pathlib import Path
from datetime import datetime
import duckdb
import pandas as pd

# -------- è·¯å¾‘è¨­å®š --------
TICK_FILES = {
    "XAUUSD": r"D:\project\ç­–ç•¥ç”¢ç”Ÿå™¨\data\Strategy_GeneratorXAUUSD_dukascopy_TICK_UTC-TICK-No Session.csv",
    "US30":   r"D:\project\ç­–ç•¥ç”¢ç”Ÿå™¨\data\Strategy_GeneratorUSA30IDXUSD_dukascopy_TICK_UTC-TICK-No Session.csv",
    "US100":  r"D:\project\ç­–ç•¥ç”¢ç”Ÿå™¨\data\Strategy_GeneratorUSATECHIDXUSD_dukascopy_TICK_UTC-TICK-No Session.csv",
}

DB_PATH = Path("database/market_data.duckdb")
BACKUP_DIR = Path("database")
BACKUP_DIR.mkdir(exist_ok=True)

TIMEFRAMES = {
    "M1": "1min",
    "M5": "5min",
    "M15": "15min",
    "M30": "30min",
    "H1": "1h",
    "H4": "4h",
    "D1": "1D",
}

CHUNK_ROWS = 2_000_000  # æ¯æ¬¡è®€å– Tick è¡Œæ•¸ï¼Œå¯ä¾ç¡¬é«”èª¿å¤§æˆ–èª¿å°

# -------- è¼”åŠ©å‡½å¼ --------

def backup_db():
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = BACKUP_DIR / f"market_data_rebuild_backup_{ts}.duckdb"
    shutil.copy2(DB_PATH, backup_path)
    print(f"âœ… è³‡æ–™åº«å‚™ä»½è‡³ {backup_path}")


def init_schema(conn: duckdb.DuckDBPyConnection):
    """åˆªé™¤èˆŠè³‡æ–™ä¸¦ç¢ºä¿è¡¨å­˜åœ¨ (ä¸æ”¹æ¬„ä½å‹åˆ¥)"""
    tables_to_truncate = [
        "candlestick_data",
        "candlestick_data_new",
        "tick_data",
        "swing_data",
        "algorithm_statistics",
    ]
    for tbl in tables_to_truncate:
        try:
            conn.execute(f"DELETE FROM {tbl}")
            print(f"ğŸ—‘ï¸  æ¸…ç©º {tbl}")
        except duckdb.CatalogException:
            # è¡¨ä¸å­˜åœ¨ï¼Œè·³é
            pass

    # symbols & timeframes (ç¶­åº¦)
    conn.execute("DELETE FROM symbols")
    for sym in TICK_FILES.keys():
        conn.execute("INSERT INTO symbols(symbol) VALUES (?)", [sym])
    print("âœ… symbols æ›´æ–°å®Œæˆ")

    # timeframes è‹¥ä¸å­˜åœ¨å‰‡æ–°å¢
    for tf, freq in TIMEFRAMES.items():
        conn.execute(
            "INSERT OR REPLACE INTO timeframes(code, seconds) VALUES (?, ?)",
            [tf, pd.Timedelta(freq).total_seconds()],
        )
    print("âœ… timeframes æ›´æ–°å®Œæˆ")

    # candlestick_data_new è‹¥ä¸å­˜åœ¨å‰‡å‰µå»º (ç°¡åŒ–ç‰ˆ DDL)
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS candlestick_data_new (
          id          BIGINT PRIMARY KEY,
          symbol      TEXT NOT NULL,
          timeframe   TEXT NOT NULL,
          timestamp   TIMESTAMP NOT NULL,
          open        DECIMAL(20,10) NOT NULL,
          high        DECIMAL(20,10) NOT NULL,
          low         DECIMAL(20,10) NOT NULL,
          close       DECIMAL(20,10) NOT NULL,
          volume      DECIMAL(38,18) NOT NULL,
          data_version TEXT NOT NULL,
          data_source  TEXT,
          created_at   TIMESTAMP DEFAULT now(),
          updated_at   TIMESTAMP DEFAULT now(),
          UNIQUE(symbol,timeframe,timestamp,data_version)
        )
        """
    )

    # é‡æ–°å»ºç«‹è¦–åœ– v_candlestick_latest
    conn.execute("DROP VIEW IF EXISTS v_candlestick_latest")
    conn.execute(
        """
        CREATE VIEW v_candlestick_latest AS
        SELECT * EXCLUDE rn
        FROM (
          SELECT *, ROW_NUMBER() OVER (PARTITION BY symbol,timeframe,timestamp ORDER BY data_version DESC, updated_at DESC) AS rn
          FROM candlestick_data_new
        ) WHERE rn=1;
        """
    )
    print("âœ… schema åˆå§‹åŒ–å®Œæˆ")


def process_tick_file(symbol: str, path: str, conn: duckdb.DuckDBPyConnection):
    """è®€å– Tick CSVï¼Œåˆ†æ‰¹è¨ˆç®— K ç·šä¸¦å¯«å…¥ DB"""
    print(f"\nğŸš€ è™•ç† {symbol} Tick -> Candles ...")
    idx_start = conn.execute("SELECT COALESCE(MAX(id),0) FROM candlestick_data_new").fetchone()[0]
    id_counter = idx_start
    chunk_count = 0

    for chunk in pd.read_csv(path, chunksize=CHUNK_ROWS):
        chunk_count += 1
        print(f"  ğŸ“Š è™•ç†ç¬¬ {chunk_count} æ‰¹ ({len(chunk)} ç­† ticks)...")
        
        # CSV å…·æœ‰: DateTime,Bid,Ask,Volume
        chunk.rename(columns={"DateTime": "timestamp"}, inplace=True)
        chunk["timestamp"] = pd.to_datetime(chunk["timestamp"], utc=True)
        # è½‰ mid price
        chunk["price"] = (chunk["Bid"] + chunk["Ask"]) / 2
        chunk.set_index("timestamp", inplace=True)

        for tf, freq in TIMEFRAMES.items():
            ohlcv = chunk["price"].resample(freq, label="left", closed="left").ohlc()
            vol   = chunk["Volume"].resample(freq, label="left", closed="left").sum()
            df_tf = pd.concat([ohlcv, vol], axis=1).dropna()
            df_tf.reset_index(inplace=True)
            if df_tf.empty:
                continue

            records = []
            for _, row in df_tf.iterrows():
                id_counter += 1
                records.append(
                    (
                        id_counter,
                        symbol,
                        tf,
                        row["timestamp"],
                        round(row["open"], 10),
                        round(row["high"], 10),
                        round(row["low"], 10),
                        round(row["close"], 10),
                        round(row["Volume"], 18),
                        "v1.0",
                        "rebuild",
                        datetime.now(),
                        datetime.now(),
                    )
                )
            # æ‰¹æ¬¡æ’å…¥
            if records:
                conn.executemany(
                    """
                    INSERT INTO candlestick_data_new
                    (id,symbol,timeframe,timestamp,open,high,low,close,volume,data_version,data_source,created_at,updated_at)
                    VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?)
                    """,
                    records,
                )
                print(f"    â†³ {tf}: å¯«å…¥ {len(records)} æ ¹ K ç·š")

    print(f"âœ… {symbol} å®Œæˆï¼Œç¸½å…±å¯«å…¥ {id_counter - idx_start} æ ¹ K ç·š")


def main():
    if not DB_PATH.exists():
        print(f"æ‰¾ä¸åˆ°è³‡æ–™åº« {DB_PATH}")
        sys.exit(1)

    backup_db()

    conn = duckdb.connect(DB_PATH.as_posix())
    try:
        init_schema(conn)
        for sym, fpath in TICK_FILES.items():
            if not os.path.isfile(fpath):
                print(f"âš ï¸  æ‰¾ä¸åˆ° {sym} Tick æª”æ¡ˆ: {fpath}ï¼Œè·³é")
                continue
            process_tick_file(sym, fpath, conn)

        print("\nğŸ‰ å…¨éƒ¨å•†å“ K ç·šé‡å»ºå®Œæˆï¼")
    finally:
        conn.close()
        print("ğŸ”’ è³‡æ–™åº«é€£ç·šå·²é—œé–‰")

if __name__ == "__main__":
    main() 