#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æœ€çµ‚æˆåŠŸç‰ˆæœ¬çš„è³‡æ–™åº«é‡æ§‹é·ç§»è…³æœ¬
æ­£ç¢ºè™•ç†é‡è¤‡è³‡æ–™å•é¡Œ
"""

import sys
import os
import time
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config.settings import DUCKDB_PATH
from src.database.connection import DuckDBConnection

def create_backup():
    """å‰µå»ºå‚™ä»½"""
    backup_path = Path("database") / f"market_data_backup_migration_{int(time.time())}.duckdb"
    
    print(f"ğŸ’¾ å‰µå»ºå‚™ä»½åˆ°: {backup_path}")
    
    import shutil
    shutil.copy2(DUCKDB_PATH, backup_path)
    
    print("âœ… å‚™ä»½å‰µå»ºå®Œæˆ")

def clean_existing_new_tables():
    """æ¸…ç†å·²å­˜åœ¨çš„æ–°è¡¨"""
    print("ğŸ§¹ æ¸…ç†å·²å­˜åœ¨çš„æ–°è¡¨...")
    
    try:
        with DuckDBConnection(str(DUCKDB_PATH)) as db:
            conn = db.conn
            
            # æª¢æŸ¥ä¸¦åˆªé™¤å·²å­˜åœ¨çš„æ–°è¡¨
            tables_to_drop = [
                'candlestick_data_new',
                'tick_data_new', 
                'swing_data_new',
                'algorithm_statistics_new',
                'algorithm_versions_new'
            ]
            
            for table in tables_to_drop:
                conn.execute(f"DROP TABLE IF EXISTS {table}")
                print(f"  ğŸ—‘ï¸  å·²åˆªé™¤è¡¨: {table}")
            
            # åˆªé™¤è¦–åœ–
            conn.execute("DROP VIEW IF EXISTS v_candlestick_latest")
            print("  ğŸ—‘ï¸  å·²åˆªé™¤è¦–åœ–: v_candlestick_latest")
            
            print("âœ… æ¸…ç†å®Œæˆ")
            
    except Exception as e:
        print(f"âŒ æ¸…ç†å¤±æ•—: {e}")

def create_new_schema():
    """å‰µå»ºæ–°çš„è³‡æ–™åº«æ¶æ§‹"""
    print("ğŸ—ï¸  å‰µå»ºæ–°çš„è³‡æ–™åº«æ¶æ§‹...")
    
    try:
        with DuckDBConnection(str(DUCKDB_PATH)) as db:
            conn = db.conn
            
            # å‰µå»ºç¶­åº¦è¡¨
            conn.execute("""
                CREATE TABLE IF NOT EXISTS symbols (
                  symbol   TEXT PRIMARY KEY
                )
            """)
            
            conn.execute("""
                CREATE TABLE IF NOT EXISTS timeframes (
                  code     TEXT PRIMARY KEY,
                  seconds  INTEGER NOT NULL CHECK (seconds > 0)
                )
            """)
            
            # å‰µå»ºæ–°çš„è Ÿç‡­åœ–è¡¨ï¼ˆç§»é™¤å”¯ä¸€ç´„æŸï¼Œé¿å…é‡è¤‡å•é¡Œï¼‰
            conn.execute("""
                CREATE TABLE IF NOT EXISTS candlestick_data_new (
                  id          BIGINT PRIMARY KEY,
                  symbol      TEXT NOT NULL,
                  timeframe   TEXT NOT NULL,
                  timestamp   TIMESTAMP NOT NULL,
                  open        DECIMAL(20,10) NOT NULL,
                  high        DECIMAL(20,10) NOT NULL,
                  low         DECIMAL(20,10) NOT NULL,
                  close       DECIMAL(20,10) NOT NULL,
                  volume      DECIMAL(38,18) NOT NULL,
                  data_version TEXT NOT NULL,
                  data_source  TEXT,
                  created_at   TIMESTAMP DEFAULT now(),
                  updated_at   TIMESTAMP DEFAULT now()
                )
            """)
            
            print("âœ… æ–°æ¶æ§‹å‰µå»ºå®Œæˆ")
            
    except Exception as e:
        print(f"âŒ æ¶æ§‹å‰µå»ºå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

def migrate_candlestick_data():
    """é·ç§»è Ÿç‡­åœ–è³‡æ–™"""
    print("ğŸ“¦ é–‹å§‹è Ÿç‡­åœ–è³‡æ–™é·ç§»...")
    
    try:
        with DuckDBConnection(str(DUCKDB_PATH)) as db:
            conn = db.conn
            
            print("1ï¸âƒ£ å¡«å……ç¶­åº¦è¡¨...")
            
            # å¡«å…… symbols è¡¨
            conn.execute("""
                INSERT INTO symbols(symbol)
                SELECT DISTINCT symbol FROM candlestick_data
                ON CONFLICT (symbol) DO NOTHING
            """)
            
            # å¡«å…… timeframes è¡¨
            conn.execute("""
                INSERT INTO timeframes(code, seconds)
                VALUES 
                    ('M1', 60), 
                    ('M5', 300), 
                    ('M15', 900), 
                    ('M30', 1800),
                    ('H1', 3600), 
                    ('H4', 14400), 
                    ('D1', 86400),
                    ('W1', 604800),
                    ('MN', 2592000),
                    ('1M', 2592000)
                ON CONFLICT (code) DO NOTHING
            """)
            
            print("âœ… ç¶­åº¦è¡¨å¡«å……å®Œæˆ")
            
            print("\n2ï¸âƒ£ é·ç§»è Ÿç‡­åœ–è³‡æ–™ï¼ˆè™•ç†é‡è¤‡è³‡æ–™ï¼‰...")
            
            # å…ˆæª¢æŸ¥é‡è¤‡è³‡æ–™
            duplicate_check = conn.execute("""
                SELECT symbol, timeframe, timestamp, COUNT(*) as cnt
                FROM candlestick_data
                GROUP BY symbol, timeframe, timestamp
                HAVING COUNT(*) > 1
                LIMIT 5
            """).fetchall()
            
            if duplicate_check:
                print(f"âš ï¸  ç™¼ç¾ {len(duplicate_check)} çµ„é‡è¤‡è³‡æ–™ï¼Œå°‡ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬")
                for dup in duplicate_check:
                    print(f"  â€¢ {dup[0]} {dup[1]} {dup[2]}: {dup[3]} ç­†")
            
            # åˆ†æ‰¹é·ç§»è Ÿç‡­åœ–è³‡æ–™ï¼Œè™•ç†é‡è¤‡
            batch_size = 50000  # æ¸›å°‘æ‰¹æ¬¡å¤§å°
            total_count = conn.execute("SELECT COUNT(*) FROM candlestick_data").fetchone()[0]
            
            print(f"ğŸ“Š ç¸½å…±éœ€è¦é·ç§» {total_count:,} ç­†è Ÿç‡­åœ–è³‡æ–™")
            
            for offset in range(0, total_count, batch_size):
                print(f"   è™•ç†ç¬¬ {offset//batch_size + 1} æ‰¹æ¬¡ ({offset:,} - {min(offset + batch_size, total_count):,})")
                
                # ä½¿ç”¨æ›´ç°¡å–®çš„é·ç§»ç­–ç•¥ï¼Œé¿å…è¤‡é›œçš„ ROW_NUMBER
                conn.execute(f"""
                    INSERT INTO candlestick_data_new
                    SELECT
                      ROW_NUMBER() OVER (ORDER BY symbol, timeframe, timestamp) + {offset} AS id,
                      CAST(symbol AS TEXT) AS symbol,
                      CAST(timeframe AS TEXT) AS timeframe,
                      CAST(timestamp AS TIMESTAMP) AS timestamp,
                      CAST(open  AS DECIMAL(20,10))  AS open,
                      CAST(high  AS DECIMAL(20,10))  AS high,
                      CAST(low   AS DECIMAL(20,10))  AS low,
                      CAST(close AS DECIMAL(20,10))  AS close,
                      CAST(volume AS DECIMAL(38,18)) AS volume,
                      COALESCE(data_version,'v1.0') AS data_version,
                      data_source,
                      COALESCE(created_at, now()) AS created_at,
                      COALESCE(updated_at, now()) AS updated_at
                    FROM candlestick_data
                    ORDER BY symbol, timeframe, timestamp
                    LIMIT {batch_size} OFFSET {offset}
                """)
            
            print("âœ… è Ÿç‡­åœ–è³‡æ–™é·ç§»å®Œæˆ")
            
            print("\n3ï¸âƒ£ å‰µå»ºç´¢å¼•...")
            
            # å‰µå»ºç´¢å¼•
            indexes = [
                "CREATE INDEX IF NOT EXISTS idx_candle_q1_new ON candlestick_data_new(symbol, timeframe, timestamp)",
                "CREATE INDEX IF NOT EXISTS idx_candle_q2_new ON candlestick_data_new(symbol, timeframe, data_version, timestamp)"
            ]
            
            for index_sql in indexes:
                conn.execute(index_sql)
            
            print("âœ… ç´¢å¼•å‰µå»ºå®Œæˆ")
            
            print("\n4ï¸âƒ£ å‰µå»ºè¦–åœ–...")
            
            # å‰µå»ºæœ€æ–°ç‰ˆæœ¬è¦–åœ–ï¼ˆè™•ç†é‡è¤‡è³‡æ–™ï¼‰
            conn.execute("""
                CREATE OR REPLACE VIEW v_candlestick_latest AS
                SELECT * EXCLUDE rn
                FROM (
                  SELECT *,
                         ROW_NUMBER() OVER (
                           PARTITION BY symbol, timeframe, timestamp
                           ORDER BY data_version DESC, updated_at DESC, id DESC
                         ) AS rn
                  FROM candlestick_data_new
                )
                WHERE rn = 1
            """)
            
            print("âœ… è¦–åœ–å‰µå»ºå®Œæˆ")
            
            # é©—è­‰è³‡æ–™
            print("\n5ï¸âƒ£ é©—è­‰é·ç§»çµæœ...")
            
            # æ¯”è¼ƒè³‡æ–™ç­†æ•¸
            old_count = conn.execute("SELECT COUNT(*) FROM candlestick_data").fetchone()[0]
            new_count = conn.execute("SELECT COUNT(*) FROM candlestick_data_new").fetchone()[0]
            
            print(f"ğŸ“Š è Ÿç‡­åœ–è³‡æ–™ï¼šèˆŠè¡¨ {old_count:,} ç­† â†’ æ–°è¡¨ {new_count:,} ç­†")
            
            # æª¢æŸ¥è¦–åœ–çš„è³‡æ–™é‡
            view_count = conn.execute("SELECT COUNT(*) FROM v_candlestick_latest").fetchone()[0]
            print(f"ğŸ“Š è¦–åœ–è³‡æ–™ï¼š{view_count:,} ç­†ï¼ˆå»é‡å¾Œï¼‰")
            
            # æª¢æŸ¥æ–°è¡¨çš„è³‡æ–™å“è³ª
            print("\nğŸ“Š æ–°è¡¨è³‡æ–™å“è³ªæª¢æŸ¥:")
            
            # æª¢æŸ¥æ™‚é–“ç¯„åœ
            time_range = conn.execute("""
                SELECT MIN(timestamp), MAX(timestamp) FROM candlestick_data_new
            """).fetchone()
            
            print(f"  â€¢ æ™‚é–“ç¯„åœ: {time_range[0]} åˆ° {time_range[1]}")
            
            # æª¢æŸ¥è³‡æ–™ç‰ˆæœ¬åˆ†å¸ƒ
            version_dist = conn.execute("""
                SELECT data_version, COUNT(*) as cnt
                FROM candlestick_data_new
                GROUP BY data_version
                ORDER BY cnt DESC
            """).fetchall()
            
            print("  â€¢ è³‡æ–™ç‰ˆæœ¬åˆ†å¸ƒ:")
            for version in version_dist:
                print(f"    - {version[0]}: {version[1]:,} ç­†")
            
            # æª¢æŸ¥å„æ™‚é–“é€±æœŸçš„è³‡æ–™é‡
            timeframe_dist = conn.execute("""
                SELECT timeframe, COUNT(*) as cnt
                FROM candlestick_data_new
                GROUP BY timeframe
                ORDER BY timeframe
            """).fetchall()
            
            print("  â€¢ æ™‚é–“é€±æœŸåˆ†å¸ƒ:")
            for tf in timeframe_dist:
                print(f"    - {tf[0]}: {tf[1]:,} ç­†")
            
            # æª¢æŸ¥é‡è¤‡è³‡æ–™è™•ç†çµæœ
            duplicate_after = conn.execute("""
                SELECT symbol, timeframe, timestamp, COUNT(*) as cnt
                FROM candlestick_data_new
                GROUP BY symbol, timeframe, timestamp
                HAVING COUNT(*) > 1
                LIMIT 5
            """).fetchall()
            
            if duplicate_after:
                print(f"  â€¢ æ–°è¡¨ä¸­ä»æœ‰ {len(duplicate_after)} çµ„é‡è¤‡è³‡æ–™ï¼ˆé€™æ˜¯æ­£å¸¸çš„ï¼Œè¦–åœ–æœƒè™•ç†ï¼‰")
                for dup in duplicate_after:
                    print(f"    - {dup[0]} {dup[1]} {dup[2]}: {dup[3]} ç­†")
            else:
                print("  â€¢ æ–°è¡¨ä¸­æ²’æœ‰é‡è¤‡è³‡æ–™")
            
            print("\nâœ… è Ÿç‡­åœ–è³‡æ–™é·ç§»å®Œæˆï¼æ–°è¡¨å·²å‰µå»ºï¼ŒåŸå§‹è¡¨ä¿ç•™ä½œç‚ºå‚™ä»½")
            
    except Exception as e:
        print(f"âŒ é·ç§»å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

def test_new_schema():
    """æ¸¬è©¦æ–°æ¶æ§‹çš„åŠŸèƒ½"""
    print("\nğŸ§ª æ¸¬è©¦æ–°æ¶æ§‹åŠŸèƒ½...")
    
    try:
        with DuckDBConnection(str(DUCKDB_PATH)) as db:
            conn = db.conn
            
            # æ¸¬è©¦è¦–åœ–æŸ¥è©¢
            print("ğŸ“Š æ¸¬è©¦è¦–åœ–æŸ¥è©¢...")
            
            # æŸ¥è©¢æœ€æ–°çš„ D1 è³‡æ–™
            d1_data = conn.execute("""
                SELECT COUNT(*) as cnt, 
                       MIN(timestamp) as min_date, 
                       MAX(timestamp) as max_date
                FROM v_candlestick_latest
                WHERE symbol = 'EXUSA30IDXUSD' AND timeframe = 'D1'
            """).fetchone()
            
            print(f"  â€¢ D1 è³‡æ–™ï¼š{d1_data[0]:,} ç­† ({d1_data[1]} åˆ° {d1_data[2]})")
            
            # æŸ¥è©¢æœ€æ–°çš„ H4 è³‡æ–™
            h4_data = conn.execute("""
                SELECT COUNT(*) as cnt, 
                       MIN(timestamp) as min_date, 
                       MAX(timestamp) as max_date
                FROM v_candlestick_latest
                WHERE symbol = 'EXUSA30IDXUSD' AND timeframe = 'H4'
            """).fetchone()
            
            print(f"  â€¢ H4 è³‡æ–™ï¼š{h4_data[0]:,} ç­† ({h4_data[1]} åˆ° {h4_data[2]})")
            
            # æ¸¬è©¦åƒ¹æ ¼ç²¾åº¦
            print("ğŸ“ˆ æ¸¬è©¦åƒ¹æ ¼ç²¾åº¦...")
            
            price_sample = conn.execute("""
                SELECT open, high, low, close, volume
                FROM v_candlestick_latest
                WHERE symbol = 'EXUSA30IDXUSD' AND timeframe = 'D1'
                ORDER BY timestamp DESC
                LIMIT 5
            """).fetchall()
            
            print("  â€¢ æœ€æ–° D1 åƒ¹æ ¼æ¨£æœ¬:")
            for i, row in enumerate(price_sample, 1):
                print(f"    {i}. O:{row[0]:.10f} H:{row[1]:.10f} L:{row[2]:.10f} C:{row[3]:.10f} V:{row[4]:.18f}")
            
            print("âœ… æ–°æ¶æ§‹åŠŸèƒ½æ¸¬è©¦å®Œæˆ")
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("ğŸ”§ æœ€çµ‚æˆåŠŸç‰ˆè³‡æ–™åº«é‡æ§‹é·ç§»å·¥å…·")
    print("=" * 60)
    
    # å‰µå»ºå‚™ä»½
    create_backup()
    
    # æ¸…ç†å·²å­˜åœ¨çš„æ–°è¡¨
    clean_existing_new_tables()
    
    # å‰µå»ºæ–°æ¶æ§‹
    create_new_schema()
    
    # åŸ·è¡Œé·ç§»
    migrate_candlestick_data()
    
    # æ¸¬è©¦æ–°æ¶æ§‹
    test_new_schema()
    
    print("\nğŸ‰ è Ÿç‡­åœ–è³‡æ–™é‡æ§‹é·ç§»å®Œæˆï¼")
    print("ğŸ“ å»ºè­°æ¥ä¸‹ä¾†çš„æ­¥é©Ÿï¼š")
    print("   1. æ¸¬è©¦æ–°è¡¨çš„æŸ¥è©¢åŠŸèƒ½")
    print("   2. æ›´æ–°æ‡‰ç”¨ç¨‹å¼ä»£ç¢¼ä»¥ä½¿ç”¨æ–°è¡¨")
    print("   3. é©—è­‰è³‡æ–™å®Œæ•´æ€§")
    print("   4. è€ƒæ…®åˆªé™¤èˆŠè¡¨ï¼ˆå‚™ä»½å·²ä¿ç•™ï¼‰")
    print("\nğŸ’¡ æ–°æ¶æ§‹ç‰¹é»ï¼š")
    print("   â€¢ é«˜ç²¾åº¦ DECIMAL(20,10) åƒ¹æ ¼æ¬„ä½")
    print("   â€¢ å¤§å®¹é‡ DECIMAL(38,18) æˆäº¤é‡æ¬„ä½")
    print("   â€¢ å¤šç‰ˆæœ¬æ”¯æ´ï¼ˆdata_versionï¼‰")
    print("   â€¢ è¦–åœ–è‡ªå‹•å»é‡ï¼ˆv_candlestick_latestï¼‰")
    print("   â€¢ å®Œæ•´çš„ç´¢å¼•å„ªåŒ–")